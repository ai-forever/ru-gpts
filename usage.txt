export CUDA_VISIBLE_DEVICES=2

python generate_transformers.py \
    --model_type=gpt2 \
    --model_name_or_path=/home/u/gpt2_large_bbpe_v50 \
    --k=10 \
    --p=0.9

python pretrain_transformers.py \
    --block_size=1023 \
    --train_data_file=/home/u/gpt_text/pelevin_train.txt \
    --output_dir=/home/u/gpt2_large_bbpe_v50 \
    --model_type=gpt2 \
    --model_name_or_path=/home/u/gpt2_large_bbpe_v50 \
    --do_eval \
    --eval_data_file=/home/u/gpt_text/tolstoy_valid.txt \
    --fp16

# perplexity = tensor(14.0039)    

python pretrain_transformers.py \
    --block_size=1023 \
    --train_data_file=/home/u/gpt_text/pelevin_train.txt \
    --output_dir=/home/u/gpt2_large_bbpe_v50 \
    --model_type=gpt2 \
    --model_name_or_path=/home/u/gpt2_large_bbpe_v50 \
    --do_eval \
    --eval_data_file=/home/u/gpt_text/pelevin_valid.txt \
    --fp16

# perplexity = tensor(18.5913)

python pretrain_transformers.py \
    --block_size=1023 \
    --output_dir=/home/u/gpt2_large_bbpe_v50/checkpoints \
    --model_type=gpt2 \
    --model_name_or_path=/home/u/gpt2_large_bbpe_v50 \
    --do_train \
    --train_data_file=/home/u/gpt_text/pelevin_train.txt \
    --save_steps=1129 \
    --do_eval \
    --eval_data_file=/home/u/gpt_text/pelevin_valid.txt \
    --fp16

test