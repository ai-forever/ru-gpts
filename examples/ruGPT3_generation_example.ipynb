{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT generation example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScihOkrU8mzF"
      },
      "source": [
        "# How to generate text with ruGPTs models?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dktqThMB_qlM"
      },
      "source": [
        "### Install enviroment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWk_Cl9qn0O-",
        "outputId": "db69bc3d-e39c-480a-aeac-f9cdfff7b659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/sberbank-ai/ru-gpts/master/generate_transformers.py"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-23 11:25:36--  https://raw.githubusercontent.com/sberbank-ai/ru-gpts/master/generate_transformers.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10472 (10K) [text/plain]\n",
            "Saving to: ‘generate_transformers.py.1’\n",
            "\n",
            "generate_transforme 100%[===================>]  10.23K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-10-23 11:25:36 (60.9 MB/s) - ‘generate_transformers.py.1’ saved [10472/10472]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx50iHm3FqTL"
      },
      "source": [
        "Here your mabe need to restart colab notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yzxF35lAZZ1"
      },
      "source": [
        "!pip3 install urllib3==1.25.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1bnQrMb_WM4"
      },
      "source": [
        "!pip3 install transformers==2.8.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIHQP__UB0U8"
      },
      "source": [
        "### Run generation script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8DYR4d6_-w7",
        "outputId": "0f6adecd-5967-4c3a-ec1e-98f792ca03a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python generate_transformers.py \\\n",
        "    --model_type=gpt2 \\\n",
        "    --model_name_or_path=sberbank-ai/rugpt3large_based_on_gpt2 \\\n",
        "    --k=5 \\\n",
        "    --p=0.95 \\\n",
        "    --length=100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-23 11:44:30.538874: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "10/23/2020 11:44:34 - INFO - transformers.tokenization_utils -   Model name 'sberbank-ai/rugpt3large_based_on_gpt2' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming 'sberbank-ai/rugpt3large_based_on_gpt2' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "10/23/2020 11:44:35 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3large_based_on_gpt2/vocab.json from cache at /root/.cache/torch/transformers/39e50567636d4014628a4fb0b7665a179a6109d96765eb4e6a10e9f2306f963d.de52bc5880aff0437c7f24c33b71ecae48f6f03f0449dfe933503132c6c1cc26\n",
            "10/23/2020 11:44:35 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3large_based_on_gpt2/merges.txt from cache at /root/.cache/torch/transformers/0a94bcfc9ca640e268e53959b05f2ebe267a5cb686289b46cac4ffac589eac40.5885500c9887f152893bfadf3b511a9105243c57bfc45889e3552bdc61090032\n",
            "10/23/2020 11:44:35 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3large_based_on_gpt2/added_tokens.json from cache at None\n",
            "10/23/2020 11:44:35 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3large_based_on_gpt2/special_tokens_map.json from cache at None\n",
            "10/23/2020 11:44:35 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3large_based_on_gpt2/tokenizer_config.json from cache at None\n",
            "10/23/2020 11:44:36 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3large_based_on_gpt2/config.json from cache at /root/.cache/torch/transformers/53218293a9edec913332b4f2d178496a60f98d64a1af74f92984804152f9404c.02a103afdbdbf4896cc41fc6495e47b7e5e2f353a287fe98d178e669be028903\n",
            "10/23/2020 11:44:36 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"_num_labels\": 2,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bad_words_ids\": null,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"finetuning_task\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 2048,\n",
            "  \"n_embd\": 1536,\n",
            "  \"n_head\": 16,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 24,\n",
            "  \"n_positions\": 2048,\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": null,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "10/23/2020 11:44:36 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/sberbank-ai/rugpt3large_based_on_gpt2/pytorch_model.bin from cache at /root/.cache/torch/transformers/5f2ce73f5df1b0b20e9c0d5fadbedefdc9b484edcbc39252a1c913b1b4ce6cd2.5bdac7adaf803c2b7192441aba3020af4140f7177089f8f95940a0c073059a31\n",
            "10/23/2020 11:45:50 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in GPT2LMHeadModel: ['transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.11.attn.masked_bias', 'transformer.h.12.attn.masked_bias', 'transformer.h.13.attn.masked_bias', 'transformer.h.14.attn.masked_bias', 'transformer.h.15.attn.masked_bias', 'transformer.h.16.attn.masked_bias', 'transformer.h.17.attn.masked_bias', 'transformer.h.18.attn.masked_bias', 'transformer.h.19.attn.masked_bias', 'transformer.h.20.attn.masked_bias', 'transformer.h.21.attn.masked_bias', 'transformer.h.22.attn.masked_bias', 'transformer.h.23.attn.masked_bias']\n",
            "10/23/2020 11:45:56 - INFO - __main__ -   Namespace(device=device(type='cuda'), k=5, length=100, model_name_or_path='sberbank-ai/rugpt3large_based_on_gpt2', model_type='gpt2', n_gpu=1, no_cuda=False, num_return_sequences=1, p=0.95, padding_text='', prompt='', repetition_penalty=1.0, seed=42, stop_token='</s>', temperature=1.0, xlm_language='')\n",
            "Context >>> Бразильские ученые открыли редкий вид карликовых единорогов, обитающих на западе Ютландии.\n",
            "10/23/2020 11:46:30 - WARNING - transformers.modeling_utils -   Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
            "ruGPT:\n",
            "Бразильские ученые открыли редкий вид карликовых единорогов, обитающих на западе Ютландии. Об этом сообщает Agence France-Presse. Единорог, получивший название Pygmaea cristata (P. cristata), был описан в 2011 году и назван в честь бразильского зоолога Фернандо Пабло Кастеллано (F. Fernando Castellano). По словам ученых, карликовые единорожки имеют размер около 1,8 метра, а длина тела составляет около 2,6 метра. В длину они достигают примерно 2\n",
            "Context >>> "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rZAwIvXG31F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}